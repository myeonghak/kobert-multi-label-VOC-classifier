{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 align=\"center\">KoBERT Multi-label text classifier</h1></h1>\n",
    "    <h4 align=\"center\">By: Myeonghak Lee</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Data 가공 파트\n",
    "\n",
    "# import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import config\n",
    "from config import expand_pandas\n",
    "from preprocess import preprocess\n",
    "\n",
    "DATA_PATH=config.DATA_PATH\n",
    "\n",
    "model_config=config.model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "config.expand_pandas(max_rows=100, max_cols=100,width=1000,max_info_cols=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class=17\n",
    "ver_num=1\n",
    "\n",
    "except_labels=[\"변경/취소\",\"예약기타\"]\n",
    "\n",
    "version_info=\"{:02d}\".format(ver_num)\n",
    "weight_path=f\"../weights/weight_{version_info}.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_orig=data.voc_total[\"종합본\"]\n",
    "data.make_table()\n",
    "\n",
    "# put labels\n",
    "data.label_process(num_labels=num_class, except_labels=except_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig=data.voc_total[\"종합본\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols=data.label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dataset=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from metrics_for_multilabel import calculate_metrics, colwise_accuracy\n",
    "\n",
    "from bert_model import Data_for_BERT, BERTClassifier, EarlyStopping\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data_for_BERT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7489274f797f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_for_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_len\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_for_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_len\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Data_for_BERT' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(voc_dataset, voc_dataset[\"국내선\"], test_size = 0.25, random_state = 42)\n",
    "\n",
    "# train=pd.concat([train_input,train_target],axis=1)\n",
    "# test=pd.concat([test_input,test_target],axis=1)\n",
    "\n",
    "train=train_input.copy()\n",
    "test=test_input.copy()\n",
    "\n",
    "train=train.reset_index(drop=True)\n",
    "test=test.reset_index(drop=True)\n",
    "\n",
    "data_train = Data_for_BERT(train, model_config[\"max_len\"], True, False, label_cols=label_cols)\n",
    "data_test = Data_for_BERT(test, model_config[\"max_len\"], True, False, label_cols=label_cols)\n",
    "\n",
    "# 파이토치 모델에 넣을 수 있도록 데이터를 처리함. \n",
    "# data_train을 넣어주고, 이 테이터를 batch_size에 맞게 잘라줌. num_workers는 사용할 subprocess의 개수를 의미함(병렬 프로그래밍)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=model_config[\"batch_size\"], num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=model_config[\"batch_size\"], num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT 라이브러리에서 bertmodel을 호출함. .to() 메서드는 모델 전체를 GPU 디바이스에 옮겨 줌.\n",
    "model = BERTClassifier(num_classes=num_class, dr_rate = model_config[\"dr_rate\"]).to(device)\n",
    "\n",
    "# 옵티마이저와 스케쥴 준비 (linear warmup과 decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "# no_decay에 해당하는 파라미터명을 가진 레이어들은 decay에서 배제하기 위해 weight_decay를 0으로 셋팅, 그 외에는 0.01로 decay\n",
    "# weight decay란 l2 norm으로 파라미터 값을 정규화해주는 기법을 의미함\n",
    "optimizer_grouped_parameters = [\n",
    "    {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay' : 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "\n",
    "# 옵티마이저는 AdamW, 손실함수는 BCE\n",
    "# optimizer_grouped_parameters는 최적화할 파라미터의 그룹을 의미함\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr= model_config[\"learning_rate\"])\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn=nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# t_total = train_dataloader.dataset.labels.shape[0] * num_epochs\n",
    "# linear warmup을 사용해 학습 초기 단계(배치 초기)의 learning rate를 조금씩 증가시켜 나가다, 어느 지점에 이르면 constant하게 유지\n",
    "# 초기 학습 단계에서의 변동성을 줄여줌.\n",
    "\n",
    "t_total = len(train_dataloader) * model_config[\"num_epochs\"]\n",
    "warmup_step = int(t_total * model_config[\"warmup_ratio\"])\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "\n",
    "# model_save_name = 'classifier'\n",
    "# model_file='.pt'\n",
    "# path = f\"./bert_weights/{model_save_name}_{model_file}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, patience, n_epochs,path):\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path=path)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        # initialize the early_stopping object\n",
    "        model.train()\n",
    "        train_epoch_pred=[]\n",
    "        train_loss_record=[]\n",
    "\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "        \n",
    "            # label = label.long().to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            out= model(token_ids, valid_length, segment_ids)#.squeeze(1)\n",
    "            \n",
    "            loss = loss_fn(out, label)\n",
    "\n",
    "            train_loss_record.append(loss)\n",
    "\n",
    "            train_pred=out.detach().cpu().numpy()\n",
    "            train_real=label.detach().cpu().numpy()\n",
    "\n",
    "            train_batch_result = calculate_metrics(np.array(train_pred), np.array(train_real))\n",
    "            \n",
    "            if batch_id%50==0:\n",
    "                print(f\"batch number {batch_id}, train col-wise accuracy is : {train_batch_result['Column-wise Accuracy']}\")\n",
    "                \n",
    "\n",
    "            # save prediction result for calculation of accuracy per batch\n",
    "            train_epoch_pred.append(train_pred)\n",
    "\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), model_config[\"max_grad_norm\"])\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        train_epoch_pred=np.concatenate(train_epoch_pred)\n",
    "        train_epoch_target=train_dataloader.dataset.labels\n",
    "        train_epoch_result=calculate_metrics(target=train_epoch_target, pred=train_epoch_pred)\n",
    "        \n",
    "        print(f\"=====Training Report: mean loss is {sum(train_loss_record)/len(train_loss_record)}=====\")\n",
    "        print(train_epoch_result)\n",
    "        \n",
    "        print(\"=====train done!=====\")\n",
    "\n",
    "        # if e % log_interval == 0:\n",
    "        #     print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "\n",
    "        # print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "        test_epoch_pred=[]\n",
    "        test_loss_record=[]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, test_label) in enumerate(test_dataloader):\n",
    "                \n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length = valid_length\n",
    "                \n",
    "                # test_label = test_label.long().to(device)\n",
    "                test_label = test_label.float().to(device)\n",
    "\n",
    "                test_out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "                test_loss = loss_fn(test_out, test_label)\n",
    "\n",
    "                test_loss_record.append(test_loss)\n",
    "                \n",
    "                valid_losses.append(test_loss.item())\n",
    "\n",
    "                test_pred=test_out.detach().cpu().numpy()\n",
    "                test_real=test_label.detach().cpu().numpy()\n",
    "\n",
    "                test_batch_result = calculate_metrics(np.array(test_pred), np.array(test_real))\n",
    "\n",
    "                if batch_id%50==0:\n",
    "                    print(f\"batch number {batch_id}, test col-wise accuracy is : {test_batch_result['Column-wise Accuracy']}\")\n",
    "\n",
    "                # save prediction result for calculation of accuracy per epoch\n",
    "                test_epoch_pred.append(test_pred)\n",
    "\n",
    "        test_epoch_pred=np.concatenate(test_epoch_pred)\n",
    "        test_epoch_target=test_dataloader.dataset.labels\n",
    "        test_epoch_result=calculate_metrics(target=test_epoch_target, pred=test_epoch_pred)\n",
    "\n",
    "        print(f\"=====Testing Report: mean loss is {sum(test_loss_record)/len(test_loss_record)}=====\")\n",
    "        print(test_epoch_result)\n",
    "\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 10\n",
    "model, train_loss, valid_loss = train_model(model, \n",
    "                                            model_config[\"batch_size\"],\n",
    "                                            patience, \n",
    "                                            model_config[\"num_epochs\"], \n",
    "                                            path=weight_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path=\"../weights/weight_01.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number 0, test col-wise accuracy is : 0.9294117647058825\n",
      "batch number 50, test col-wise accuracy is : 0.9411764705882353\n",
      "batch number 100, test col-wise accuracy is : 0.9058823529411765\n",
      "=====Testing Report: mean loss is 0.20872297883033752=====\n",
      "{'Accuracy': 0.22437137330754353, 'Column-wise Accuracy': 0.9210376607122539, 'micro/precision': 0.7973273942093542, 'micro/recall': 0.372528616024974, 'micro/f1': 0.5078014184397163, 'macro/precision': 0.6019785504362263, 'macro/recall': 0.28350515905377016, 'macro/f1': 0.34598051554393844, 'samples/precision': 0.563023855577047, 'samples/recall': 0.3934235976789168, 'samples/f1': 0.4393478861563968}\n"
     ]
    }
   ],
   "source": [
    "test_epoch_pred=[] \n",
    "test_loss_record=[] \n",
    "valid_losses=[]\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad(): \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, test_label) in enumerate(test_dataloader):\n",
    "\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        \n",
    "        # test_label = test_label.long().to(device)\n",
    "        test_label = test_label.float().to(device)\n",
    "\n",
    "        test_out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        test_loss = loss_fn(test_out, test_label)\n",
    "\n",
    "        test_loss_record.append(test_loss)\n",
    "        \n",
    "        valid_losses.append(test_loss.item())\n",
    "\n",
    "        test_pred=test_out.detach().cpu().numpy()\n",
    "        test_real=test_label.detach().cpu().numpy()\n",
    "\n",
    "        test_batch_result = calculate_metrics(np.array(test_pred), np.array(test_real))\n",
    "\n",
    "        if batch_id%50==0:\n",
    "            print(f\"batch number {batch_id}, test col-wise accuracy is : {test_batch_result['Column-wise Accuracy']}\")\n",
    "\n",
    "        # save prediction result for calculation of accuracy per epoch\n",
    "        test_epoch_pred.append(test_pred)\n",
    "\n",
    "        # if batch_id%10==0:\n",
    "        #     print(test_batch_result[\"Accuracy\"])\n",
    "    test_epoch_pred=np.concatenate(test_epoch_pred) \n",
    "    test_epoch_target=test_dataloader.dataset.labels \n",
    "    test_epoch_result=calculate_metrics(target=test_epoch_target, pred=test_epoch_pred)\n",
    "\n",
    "    # print(test_epoch_pred)\n",
    "    # print(test_epoch_target)\n",
    "    print(f\"=====Testing Report: mean loss is {sum(test_loss_record)/len(test_loss_record)}=====\")\n",
    "    print(test_epoch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics_for_multilabel as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840774483390301"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_ndcg_score(test_epoch_target,test_epoch_pred, k=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6367182462927145\n"
     ]
    }
   ],
   "source": [
    "acc_cnt=0\n",
    "for n in range(test_epoch_pred.shape[0]):\n",
    "    tar_cnt=np.count_nonzero(test_epoch_target[n])\n",
    "    pred_=test_epoch_pred[n].argsort()[-tar_cnt:]\n",
    "    tar_=test_epoch_target[n].argsort()[-tar_cnt:]\n",
    "    acc_cnt+=len(set(pred_)&set(tar_))/len(pred_)\n",
    "print(f\"accuracy: {acc_cnt/test_epoch_pred.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(target=test_epoch_target, pred=test_epoch_pred, threshold=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cases_sorted_target=data.label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nlp.data.BERTSentenceTransform(tok, max_seq_length = max_len, pad=True, pair=False)\n",
    "\n",
    "def get_prediction_from_txt(input_text, threshold=0.0):\n",
    "    sentences = transform([input_text])\n",
    "    get_pred=model(torch.tensor(sentences[0]).long().unsqueeze(0).to(device),torch.tensor(sentences[1]).unsqueeze(0),torch.tensor(sentences[2]).to(device))\n",
    "    pred=np.array(get_pred.to(\"cpu\").detach().numpy()[0] > threshold, dtype=float)\n",
    "    pred=np.nonzero(pred)[0].tolist()\n",
    "    print(f\"분석 결과, 대화의 예상 태그는 {[label_cases_sorted_target[i] for i in pred]} 입니다.\")\n",
    "    true=np.nonzero(input_text_label)[0].tolist()\n",
    "    print(f\"실제 태그는 {[label_cases_sorted_target[i] for i in true]} 입니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_num=17\n",
    "input_text=voc_dataset.iloc[input_text_num,0]\n",
    "# input_text=test.iloc[input_text_num,0]\n",
    "input_text_label=voc_dataset.iloc[input_text_num,1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 결과, 대화의 예상 태그는 ['대기예약', '무상신규예약'] 입니다.\n",
      "실제 태그는 ['무상신규예약'] 입니다.\n"
     ]
    }
   ],
   "source": [
    "get_prediction_from_txt(input_text, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum_tools_vocvis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "# model = BERTClassifier(bertmodel, dr_rate = 0.4).to(device)\n",
    "# model.load_state_dict(torch.load(os.getcwd()+\"/chat_voc_model.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IND = tok.vocab.padding_token\n",
    "PAD_IND = tok.convert_tokens_to_ids(PAD_IND)\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerIntegratedGradients(model,model.bert.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nlp.data.BERTSentenceTransform(tok, max_seq_length = 64, pad=True, pair=False)\n",
    "\n",
    "voc_label_dict_inverse={ele:label_cols.index(ele) for ele in label_cols}\n",
    "\n",
    "voc_label_dict={label_cols.index(ele):ele for ele in label_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid_for_bert(input,valid_length,segment_ids):\n",
    "    return torch.sigmoid(model(input,valid_length,segment_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_for_bert(input,valid_length,segment_ids):\n",
    "    return torch.nn.functional.softmax(model(input,valid_length,segment_ids),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence, min_len = 64, label = 0, n_steps=10):\n",
    "    # text = [token for token in tok.sentencepiece(sentence)]\n",
    "    # if len(text) < min_len:\n",
    "    #     text += ['pad'] * (min_len - len(text))\n",
    "    # indexed = tok.convert_tokens_to_ids(text)\n",
    "    # print(text)\n",
    "    \n",
    "    # 토크나이징, 시퀀스 생성\n",
    "    seq_tokens=transform([sentence])\n",
    "    indexed=torch.tensor(seq_tokens[0]).long()#.to(device)\n",
    "    valid_length=torch.tensor(seq_tokens[1]).long().unsqueeze(0)\n",
    "    segment_ids=torch.tensor(seq_tokens[2]).long().unsqueeze(0).to(device)\n",
    "    sentence=[token for token in tok.sentencepiece(sentence)]\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    \n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid_for_bert(input_indices,valid_length,segment_ids).detach().cpu().numpy().argmax().item()\n",
    "    print(forward_with_sigmoid_for_bert(input_indices,valid_length,segment_ids))\n",
    "    pred_ind = round(pred)\n",
    "    \n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices,\\\n",
    "                                           n_steps=n_steps, return_convergence_delta=True,target=label,\\\n",
    "                                           additional_forward_args=(valid_length,segment_ids))\n",
    "\n",
    "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, sentence, pred, pred_ind, label, delta, vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attributions_to_visualizer(attributions, input_text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            voc_label_dict[pred_ind], #Label.vocab.itos[pred_ind],\n",
    "                            voc_label_dict[label], # Label.vocab.itos[label],\n",
    "                            100, # Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            input_text,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence=voc_dataset.iloc[22].text\n",
    "\n",
    "visualize_text(vis_data_records_ig)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "KoBERT_PoC_1211.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
